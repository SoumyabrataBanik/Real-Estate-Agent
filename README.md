# AI Real Estate Recommendation Engine

This project creates an intelligent Real Estate Recommendation application using **OpenAI**, **LangChain**, and **ChromaDB**. 

The system generates synthetic real estate listings, creates a vector database for semantic search, and employs a "Retrieval-Augmented Generation" (RAG) approach to act as an AI Realtor that recommends the best properties based on natural language user preferences.

## üìã Project Overview

The workflow consists of five distinct steps:
1.  **Environment Setup**: Configuring OpenAI API access.
2.  **Data Generation**: Using GPT-3.5 to generate structured synthetic real estate data (JSON).
3.  **Data Storage**: Converting the generated data into a CSV format.
4.  **Vector Database Creation**: Embedding descriptions and storing them in ChromaDB for semantic retrieval.
5.  **Semantic Search & Recommendation**: Querying the database with natural language and using an LLM persona ("LLMRealtor") to pitch the best matching properties.

## üõ†Ô∏è Technologies Used

*   **Python 3**
*   **Jupyter Notebook**
*   **OpenAI API** (LLM and Embeddings)
*   **LangChain** (Orchestration, Prompt Templates, Output Parsers)
*   **Pydantic** (Data Validation and Schema Definition)
*   **ChromaDB** (Vector Store)
*   **Pandas** (Data Manipulation)

## ‚öôÔ∏è Prerequisites

To run this notebook, you will need the following libraries installed. You can install them via pip:

```bash
pip install -r requirements.txt
```

## üöÄ Usage Guide

Open the `Real_Estates.ipynb` file in Jupyter Notebook or JupyterLab and execute the cells sequentially.

### Step 1: API Setup
The notebook initializes the OpenAI environment.
> **Note:** The notebook currently contains a hardcoded API key/base URL intended for a specific sandbox environment (`vocareum`). For personal use, replace the following lines with your standard OpenAI API key:

```python
import os
os.environ["OPENAI_API_KEY"] = "YOUR_ACTUAL_OPENAI_API_KEY"
# os.environ["OPENAI_API_BASE"] = ... # Remove this if using standard OpenAI
```

### Step 2: Generate Listings
The system uses `gpt-3.5-turbo` to generate at least 10 fictional real estate listings. It uses `PydanticOutputParser` to ensure the LLM outputs valid JSON containing fields like:
*   Neighborhood
*   Price
*   Bedrooms/Bathrooms
*   House Size
*   Descriptions (House & Neighborhood)

### Step 3: Create CSV
The parsed JSON data is converted into a Pandas DataFrame and saved as `Real_Estates.csv` for persistence and inspection.

### Step 4: Vector Database (ChromaDB)
1.  The CSV is loaded.
2.  The "Description" text of each property is split into chunks using `RecursiveCharacterTextSplitter`.
3.  `OpenAIEmbeddings` are used to convert text into vector representations.
4.  Vectors are stored in a local ChromaDB instance at `content/chroma`.

### Step 5: Semantic Search & AI Realtor
1.  **User Input**: You will be prompted to describe your dream house (e.g., *"A comfortable three-bedroom house with a spacious kitchen..."*).
2.  **Retrieval**: The system searches the ChromaDB for the top 3 properties semantically similar to your request.
3.  **Augmentation**: An "LLMRealtor" system prompt is combined with the retrieved listings and your original query.
4.  **Recommendation**: The AI explains why the selected properties fit your needs and recommends the single best option.

## üìÇ File Structure

*   `Real_Estates.ipynb`: The main application code.
*   `Real_Estates.csv`: Generated output containing the synthetic housing data.
*   `content/chroma/`: Directory where the Vector Database files are persisted.

## üß† How it Works (RAG Architecture)

1.  **Ingest**: Structured data is generated and descriptions are embedded.
2.  **Retrieve**: When a user asks a question, the system looks for "nearest neighbors" in the vector space‚Äîfinding listings that match the *meaning* of the request, not just keywords.
3.  **Generate**: The context (the matching listings) is fed into GPT-3.5 with a persona instructions ("You are LLMRealtor..."). The model then synthesizes a human-like response pitching the specific homes found.

## ‚ö†Ô∏è Disclaimer

This project uses synthetic data generated by an LLM. The prices, neighborhoods, and descriptions are fictional and for educational purposes only.
